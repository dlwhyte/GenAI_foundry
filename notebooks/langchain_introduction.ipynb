{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "R1oJC7t39iTJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "import warnings\n",
        "from langchain_core._api.deprecation import LangChainDeprecationWarning\n",
        "\n",
        "# Suppress LangChainDeprecationWarning only\n",
        "warnings.filterwarnings(\"ignore\", category=LangChainDeprecationWarning)\n",
        "\n",
        "# Securely input your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"üîê Enter your OpenAI API key (it will be hidden): \")\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# --- LLM Setup ---\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Prompt template with memory support\n",
        "# This defines how the AI should behave and formats each user input into a conversation turn\n",
        "# The \"system\" message sets the assistant's role, and the \"human\" message is where input gets inserted\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Maintain context of the ongoing conversation.\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "# Create a session store\n",
        "# In-memory store for chat history per user session\n",
        "# This allows tracking of conversation history across multiple turns, simulating \"memory\"\n",
        "session_store = {}\n",
        "\n",
        "# Function to load or initialize a session's memory\n",
        "# Uses ConversationBufferMemory with return_messages=True to retain full chat message formatting\n",
        "def get_session_history(session_id: str):\n",
        "    if session_id not in session_store:\n",
        "        session_store[session_id] = ConversationBufferMemory(return_messages=True)\n",
        "    return session_store[session_id].chat_memory\n",
        "\n",
        "# Build a conversational chain that combines:\n",
        "# - the prompt template\n",
        "# - the language model\n",
        "# - session-aware memory\n",
        "# RunnableWithMessageHistory handles all of this and enables persistent context per session\n",
        "chain = RunnableWithMessageHistory(\n",
        "    prompt | llm,\n",
        "    get_session_history=get_session_history,\n",
        ")\n",
        "\n",
        "# Simulate a conversation session (with 3 sequential questions)\n",
        "# The session ID acts like a \"user ID\" so the memory is preserved across turns\n",
        "session_id = \"demo-session-001\"\n",
        "questions = [\n",
        "    \"Hi, who won the World Cup in 2018?\",\n",
        "    \"And who was the top scorer?\", # This tests whether the model remembers earlier context\n",
        "    \"Was that surprising to you?\"\n",
        "]\n",
        "\n",
        "# Loop through each question, invoke the chain, and print both user + AI output\n",
        "for q in questions:\n",
        "    response = chain.invoke({\"input\": q}, config={\"configurable\": {\"session_id\": session_id}})\n",
        "    print(f\"üßë You: {q}\")\n",
        "    print(f\"ü§ñ AI: {response.content}\\n\")\n",
        "\n",
        "    # Log current memory (for educational purposes)\n",
        "    print(\"üß† Memory log so far:\")\n",
        "    for msg in get_session_history(session_id).messages:\n",
        "        print(f\"{msg.type.title()}: {msg.content}\")\n",
        "    print(\"\\n\" + \"-\"*60 + \"\\n\")"
      ]
    }
  ]
}