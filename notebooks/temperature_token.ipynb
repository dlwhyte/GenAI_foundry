{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸš€ Welcome to the Temperature and Token Explorer!\n",
        "\n",
        "This interactive Google Colab notebook allows you to interact with ChatGPT using your own API key.\n",
        "\n",
        "âœ… No advanced setup required.  \n",
        "âœ… Works with free or paid OpenAI accounts.\n",
        "\n",
        "ğŸ”§ You will need to get an OpenAI API key.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "f6dhHF63J90c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eDcjg70ZHVG",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1149318c-d729-49b4-fa73-0832dc97a9a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“˜ Interactive Multi-Prompt Text Generation with OpenAI API (Colab Form Version)\n",
        "# This notebook allows users to submit multiple prompts in a loop and view generated responses.\n",
        "\n",
        "# Step 1: Install and import the necessary libraries\n",
        "!pip install --upgrade openai > /dev/null 2>&1 # Install OpenAI SDK quietly\n",
        "\n",
        "import openai                   # OpenAI client library to interact with models\n",
        "from getpass import getpass     # Utility to hide API key input\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Step 2: Set API Key Securely\n",
        "openai.api_key = getpass(\"Enter your OpenAI API key: \")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define Completion Function\n",
        "def complete_prompt(prompt, model=\"gpt-4o-mini\", temperature=0.7, max_tokens=100):\n",
        "    try:\n",
        "        result = openai.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens,\n",
        "            stream=False\n",
        "        )\n",
        "        return result.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return f\"â— Error: {str(e)}\"\n",
        "\n",
        "# Step 4: Get Temperature and Max Tokens once (Colab Form style)\n",
        "#@title Set model behavior ğŸ¯\n",
        "temperature = 0.7 #@param {type:\"slider\", min:0.0, max:1.5, step:0.1}\n",
        "max_tokens = 100 #@param {type:\"slider\", min:10, max:300, step:10}"
      ],
      "metadata": {
        "id": "JdIdkKMqIFIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Step 5: Start multiple prompt entry loop\n",
        "print(\"âœ… Ready! Enter your prompts below. Type 'exit' to stop.\\n\")\n",
        "\n",
        "while True:\n",
        "    prompt = input(\"ğŸ“ Your prompt: \")\n",
        "    if prompt.lower() == \"exit\":\n",
        "        print(\"ğŸ‘‹ Session ended. Thank you!\")\n",
        "        break\n",
        "\n",
        "    output = complete_prompt(prompt, temperature=temperature, max_tokens=max_tokens)\n",
        "    print(\"\\nğŸ” Response:\\n\")\n",
        "    print(output)\n",
        "    print(f\"\\nğŸ§ª Generation settings â†’ Temperature: {temperature} | Max Tokens: {max_tokens}\")\n",
        "    print(\"\\n---\\n\")"
      ],
      "metadata": {
        "id": "ozs7Jzj-JSW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}